{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment #4: Extracting syntactic groups using machine-learning techniques: Keras Version\n",
    "Author: Pierre Nugues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you will create a system to extract syntactic groups from a text. You will apply it to the CoNLL 2000 dataset. You will train your models with either Keras or PyTorch. Choose one of these framework following the name of the notebook.\n",
    "\n",
    "Before you start the assignment, please run the prerequisites from the prerequistites notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objectives of this assignment are to:\n",
    "* Write a program to detect partial syntactic structures called groups or chunks\n",
    "* Understand the principles of supervised machine learning techniques applied to language processing\n",
    "* Use a popular machine learning toolkit: either Keras or PyTorch\n",
    "* Write a short report of 2 to 3 pages on the assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import bs4\n",
    "import requests\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, losses, initializers\n",
    "\n",
    "#from tensorflow.keras.utils import pad_sequences \n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical \n",
    "\n",
    "\n",
    "import conlleval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seeds\n",
    "Making things reproduceable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1234)\n",
    "np.random.seed(1234)\n",
    "tf.random.set_seed(1234)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "LSTM_HIDDEN_DIM = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may need to adjust the paths to load the datasets from your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = '/Users/filippahansen/Desktop/Språkteknologi/ilppp/programs/corpus/conll2000/train.txt'\n",
    "test_file = '/Users/filippahansen/Desktop/Språkteknologi/ilppp/programs/corpus/conll2000/test.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now convert the dataset in a Python data structure. Read the functions below to load the datasets. They store the corpus in a list of sentences. Each sentence is a list of rows, where each row is a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sentences(file):\n",
    "    \"\"\"\n",
    "    Creates a list of sentences from the corpus\n",
    "    Each sentence is a string\n",
    "    :param file:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    f = open(file).read().strip()\n",
    "    sentences = f.split('\\n\\n')\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_rows(sentences, column_names):\n",
    "    \"\"\"\n",
    "    Creates a list of sentence where each sentence is a list of lines\n",
    "    Each line is a dictionary of columns\n",
    "    :param sentences:\n",
    "    :param column_names:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    new_sentences = []\n",
    "    for sentence in sentences:\n",
    "        rows = sentence.split('\\n')\n",
    "        sentence = [dict(zip(column_names, row.split())) for row in rows]\n",
    "        new_sentences.append(sentence)\n",
    "    return new_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CoNLL 2000 files have three columns: The wordform, `form`, its part of speech, `pos`, and the tag denoting the syntactic group also called the chunk tag, `chunk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['form', 'pos', 'chunk']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the corpus as a list of dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8936"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences = read_sentences(train_file)\n",
    "train_dict = split_rows(train_sentences, column_names)\n",
    "train_dict[10:11]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'form': 'He', 'pos': 'PRP', 'chunk': 'B-NP'},\n",
       "  {'form': 'reckons', 'pos': 'VBZ', 'chunk': 'B-VP'},\n",
       "  {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       "  {'form': 'current', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
       "  {'form': 'account', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       "  {'form': 'deficit', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       "  {'form': 'will', 'pos': 'MD', 'chunk': 'B-VP'},\n",
       "  {'form': 'narrow', 'pos': 'VB', 'chunk': 'I-VP'},\n",
       "  {'form': 'to', 'pos': 'TO', 'chunk': 'B-PP'},\n",
       "  {'form': 'only', 'pos': 'RB', 'chunk': 'B-NP'},\n",
       "  {'form': '#', 'pos': '#', 'chunk': 'I-NP'},\n",
       "  {'form': '1.8', 'pos': 'CD', 'chunk': 'I-NP'},\n",
       "  {'form': 'billion', 'pos': 'CD', 'chunk': 'I-NP'},\n",
       "  {'form': 'in', 'pos': 'IN', 'chunk': 'B-PP'},\n",
       "  {'form': 'September', 'pos': 'NNP', 'chunk': 'B-NP'},\n",
       "  {'form': '.', 'pos': '.', 'chunk': 'O'}],\n",
       " [{'form': 'However', 'pos': 'RB', 'chunk': 'B-ADVP'},\n",
       "  {'form': ',', 'pos': ',', 'chunk': 'O'},\n",
       "  {'form': 'Mr.', 'pos': 'NNP', 'chunk': 'B-NP'},\n",
       "  {'form': 'Dillow', 'pos': 'NNP', 'chunk': 'I-NP'},\n",
       "  {'form': 'said', 'pos': 'VBD', 'chunk': 'B-VP'},\n",
       "  {'form': 'he', 'pos': 'PRP', 'chunk': 'B-NP'},\n",
       "  {'form': 'believes', 'pos': 'VBZ', 'chunk': 'B-VP'},\n",
       "  {'form': 'that', 'pos': 'IN', 'chunk': 'B-SBAR'},\n",
       "  {'form': 'a', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       "  {'form': 'reduction', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       "  {'form': 'in', 'pos': 'IN', 'chunk': 'B-PP'},\n",
       "  {'form': 'raw', 'pos': 'JJ', 'chunk': 'B-NP'},\n",
       "  {'form': 'material', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       "  {'form': 'stockbuilding', 'pos': 'VBG', 'chunk': 'I-NP'},\n",
       "  {'form': 'by', 'pos': 'IN', 'chunk': 'B-PP'},\n",
       "  {'form': 'industry', 'pos': 'NN', 'chunk': 'B-NP'},\n",
       "  {'form': 'could', 'pos': 'MD', 'chunk': 'B-VP'},\n",
       "  {'form': 'lead', 'pos': 'VB', 'chunk': 'I-VP'},\n",
       "  {'form': 'to', 'pos': 'TO', 'chunk': 'B-PP'},\n",
       "  {'form': 'a', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       "  {'form': 'sharp', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
       "  {'form': 'drop', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       "  {'form': 'in', 'pos': 'IN', 'chunk': 'B-PP'},\n",
       "  {'form': 'imports', 'pos': 'NNS', 'chunk': 'B-NP'},\n",
       "  {'form': '.', 'pos': '.', 'chunk': 'O'}]]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dict[10:12]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_file = '/Users/filippahansen/Desktop/Språkteknologi/ilppp/programs/corpus/conll2000/glove.6B.100d.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the function below that reads GloVe embeddings and store them in a dictionary, where the keys will be the words and the values, the embedding vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_embeddings(file):\n",
    "    \"\"\"\n",
    "    Return the embeddings in the form of a dictionary\n",
    "    :param file:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    embeddings = {}\n",
    "    glove = open(file, encoding='utf8')\n",
    "    for line in glove:\n",
    "        values = line.strip().split()\n",
    "        word = values[0]\n",
    "        vector = np.array(values[1:], dtype='float32')\n",
    "        embeddings[word] = vector\n",
    "    glove.close()\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We read the embeddings\n",
    "embeddings_dict = read_embeddings(embedding_file)\n",
    "embedded_words = sorted(list(embeddings_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# words in embedding dictionary: 400000'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'# words in embedding dictionary: {}'.format(len(embedded_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chording',\n",
       " 'chordoma',\n",
       " 'chordophones',\n",
       " 'chords',\n",
       " 'chore',\n",
       " 'chorea',\n",
       " 'chorene',\n",
       " 'choreograph',\n",
       " 'choreographed',\n",
       " 'choreographer']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_words[100000:100010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.4359   , -0.04961  ,  0.31388  ,  0.6056   ,  0.36372  ,\n",
       "       -0.03974  ,  0.42844  ,  0.58571  , -0.0048055, -0.24868  ,\n",
       "       -0.069374 ,  0.036042 , -0.68352  ,  0.55531  , -0.36235  ,\n",
       "        0.13997  ,  0.020455 , -0.82498  , -0.68761  ,  0.28685  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_dict['france'][0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.51973,  1.0395 ,  0.20924,  0.16285,  0.7209 ,  0.81524,\n",
       "       -0.34641, -0.76654, -0.49576,  0.24634,  0.44094,  0.37701,\n",
       "       -0.16396,  0.2775 ,  0.16563,  0.43869, -1.0887 ,  0.12663,\n",
       "        0.66916,  0.3578 ], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_dict['chords'][:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a cosine similarity, write a `closest(target_word, embeddings, count=10)` that computes the 10 closest words to the words _table_, _france_, and _sweden_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings_dict['chords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest(target_word, embeddings, count=10):\n",
    "    em = embeddings[target_word]\n",
    "    closest_words=list([np.dot(embeddings[word], em) / (norm(embeddings[word]) * norm(em)),word] for word in embeddings.keys())\n",
    "    closest_words.sort(reverse=True)\n",
    "    l = closest_words[0:count]\n",
    "    closest_words = [x[1] for x in l]\n",
    "    return closest_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['france',\n",
       " 'belgium',\n",
       " 'french',\n",
       " 'britain',\n",
       " 'spain',\n",
       " 'paris',\n",
       " 'germany',\n",
       " 'italy',\n",
       " 'europe',\n",
       " 'netherlands']"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest('france', embeddings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['table',\n",
       " 'tables',\n",
       " 'place',\n",
       " 'bottom',\n",
       " 'room',\n",
       " 'side',\n",
       " 'sit',\n",
       " 'top',\n",
       " 'here',\n",
       " 'pool']"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest('table', embeddings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sweden',\n",
       " 'denmark',\n",
       " 'norway',\n",
       " 'finland',\n",
       " 'netherlands',\n",
       " 'austria',\n",
       " 'switzerland',\n",
       " 'germany',\n",
       " 'swedish',\n",
       " 'belgium']"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest('sweden', embeddings_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the $\\mathbf{X}$ and $\\mathbf{Y}$ Lists of Symbols from the Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each sentence, you will build an input sequence, $\\mathbf{x}$, corresponding to the words and an output one, $\\mathbf{y}$, corresponding to the chunk tags.\n",
    "\n",
    "Write a `build_sequences(corpus_dict, key_x='form', key_y='chunk', tolower=True)` function that, for each sentence, returns the $\\mathbf{x}$ and $\\mathbf{y}$ lists of symbols consisting of words and chunk tags. Set the words in lower case if `tolower` is true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the 11th sentence of the training set, you should have:<br/>\n",
    "`x = ['he',  'reckons',  'the',  'current',  'account',  'deficit',  'will',  'narrow',  'to',  'only',  '#',  '1.8',  'billion',  'in',  'september',  '.']`\n",
    "\n",
    "`y = ['B-NP', 'B-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-VP', 'I-VP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'O']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sequences(corpus_dict, key_x='form', key_y='chunk', tolower=True):\n",
    "    X = []\n",
    "    Y = []\n",
    "    for sentence in corpus_dict:\n",
    "        if tolower:\n",
    "            x = [row[key_x].lower() for row in sentence]\n",
    "        else:\n",
    "            x = [row[key_x].lower() for row in sentence]\n",
    "        y = [row[key_y] for row in sentence]\n",
    "        \n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "    return X, Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_symbs, Y_train_symbs = build_sequences(train_dict, key_x='form', key_y='chunk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['he', 'reckons', 'the', 'current', 'account', 'deficit', 'will', 'narrow', 'to', 'only', '#', '1.8', 'billion', 'in', 'september', '.'], ['however', ',', 'mr.', 'dillow', 'said', 'he', 'believes', 'that', 'a', 'reduction', 'in', 'raw', 'material', 'stockbuilding', 'by', 'industry', 'could', 'lead', 'to', 'a', 'sharp', 'drop', 'in', 'imports', '.']]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_symbs[10:12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-NP', 'B-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-VP', 'I-VP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(Y_train_symbs[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a vocabulary of all the words observed in the training set as well as in GloVe. You should find 401,464 different words. You will proceed in two steps.\n",
    "\n",
    "First extract the list of unique words `words` from the CoNLL training set and the list of chunk tags, `chunks`. You will sort them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for sentence in train_dict:\n",
    "    for row in sentence:\n",
    "        word = row['form'].lower()\n",
    "        if word not in words:\n",
    "            words.append(word)\n",
    "chunks = []\n",
    "for sentence in train_dict:\n",
    "    for row in sentence:\n",
    "        chunk = row['chunk']\n",
    "        if chunk not in chunks:\n",
    "            chunks.append(chunk)\n",
    "words.sort()\n",
    "chunks.sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# words seen in training corpus: 17258\n",
      "# Chunks tags seen: 22\n"
     ]
    }
   ],
   "source": [
    "print('# words seen in training corpus:', len(words))\n",
    "print('# Chunks tags seen:', len(chunks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, merge the list of unique CoNLL words with the words in the embeddings file. You will sort this list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dict = embeddings_dict\n",
    "for word in words:\n",
    "    temp_dict[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_words = list(temp_dict.keys())\n",
    "vocabulary_words.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# words in the vocabulary: embeddings and corpus: 401464\n"
     ]
    }
   ],
   "source": [
    "print('# words in the vocabulary: embeddings and corpus:', len(vocabulary_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['joy',\n",
       " 'joya',\n",
       " 'joyal',\n",
       " 'joyandet',\n",
       " 'joyas',\n",
       " 'joyce',\n",
       " 'joycean',\n",
       " 'joycelyn',\n",
       " 'joyces',\n",
       " 'joydeep']"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_words[200000:200010]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the indices `word2idx`, `chunk2idx` and inverted indices `idx2word`, `idx2chunk` for the words and the chunk tags: i.e. you will associate each word with a number. You will use index 0 for the padding symbol and 1 for unknown words. This means that your first word will start at index 2. For the chunks, you will start at index 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = {}\n",
    "count = 2\n",
    "for word in vocabulary_words:\n",
    "    word2idx[word] = count\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk2idx = {}\n",
    "count = 1\n",
    "for chunk in chunks:\n",
    "    chunk2idx[chunk] = count\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2word = {}\n",
    "for idx in word2idx.items():\n",
    "    idx2word[idx[1]] = idx[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2chunk = {}\n",
    "for idx in chunk2idx.items():\n",
    "    idx2chunk[idx[1]] = idx[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('!', 2), ('!!', 3), ('!!!', 4), ('!!!!', 5), ('!!!!!', 6), ('!?', 7), ('!?!', 8), ('\"', 9), ('#', 10), ('##', 11), ('###', 12), ('#a', 13), ('#aabccc', 14), ('#b', 15), ('#c', 16), ('#cc', 17), ('#ccc', 18), ('#cccccc', 19), ('#ccccff', 20), ('#d', 21), ('#daa', 22), ('#dcdcdc', 23), ('#e', 24), ('#f', 25), ('#faf', 26)]\n"
     ]
    }
   ],
   "source": [
    "print(list(word2idx.items())[:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chunk indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('B-ADJP', 1), ('B-ADVP', 2), ('B-CONJP', 3), ('B-INTJ', 4), ('B-LST', 5), ('B-NP', 6), ('B-PP', 7), ('B-PRT', 8), ('B-SBAR', 9), ('B-UCP', 10), ('B-VP', 11), ('I-ADJP', 12), ('I-ADVP', 13), ('I-CONJP', 14), ('I-INTJ', 15), ('I-NP', 16), ('I-PP', 17), ('I-PRT', 18), ('I-SBAR', 19), ('I-UCP', 20), ('I-VP', 21), ('O', 22)]\n"
     ]
    }
   ],
   "source": [
    "print(list(chunk2idx.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a numpy matrix of dimensions $(M, N)$, where $M$ will be the size of the vocabulary: The unique words in the training set and the words in GloVe, and $N$, the dimension of the embeddings.\n",
    "The padding symbol and the unknown word symbol will be part of the vocabulary at respectively index 0 and 1. \n",
    "\n",
    "Initialize the matrix with random values with the `np.random.uniform()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We add two dimensions for the padding symbol at index 0 and unknown words at index 1\n",
    "embedding_matrix = np.random.uniform(-0.05, 0.05, (len(vocabulary_words) + 2, EMBEDDING_DIM))\n",
    "# embedding_matrix = np.random.random((len(vocabulary_words) + 2, EMBEDDING_DIM))\n",
    "# embedding_matrix = np.zeros((len(vocabulary_words) + 2, EMBEDDING_DIM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of your matrix is: (401466, 100)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(401466, 100)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill the matrix with the GloVe embeddings when available. This means: Replace the random vector with an embedding when available. You will use the indices from the previous section. You will call `out_of_embeddings` the list of words in CoNLL, but not in the embedding list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_of_embeddings = []\n",
    "for word in vocabulary_words:\n",
    "    if word in embeddings_dict.keys():\n",
    "        idx = word2idx[word]\n",
    "        embedding_matrix[idx] = embeddings_dict[word]\n",
    "    else:\n",
    "        out_of_embeddings.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1464"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out_of_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"y'all\",\n",
       " 'yankus',\n",
       " 'year-ago',\n",
       " 'year-before',\n",
       " 'year-earlier',\n",
       " 'year-to-date',\n",
       " 'yield-management',\n",
       " 'zaishuo',\n",
       " 'zarett',\n",
       " 'zumbrunn']"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_of_embeddings[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings of the padding symbol, idx 0, random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03084805,  0.01221088, -0.00622723,  0.02853586,  0.02799758,\n",
       "       -0.02274074, -0.02235357,  0.03018722,  0.04581394,  0.03759326])"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings of the word _table_, the GloVe values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.61453998,  0.89692998,  0.56770998,  0.39102   , -0.22437   ,\n",
       "        0.49035001,  0.10868   ,  0.27410999, -0.23833001, -0.52152997])"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[word2idx['table']][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings of _zarett_, a word in CoNLL 2000, but not in GloVe, random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04485961, -0.01950363,  0.03356147, -0.02404349, -0.04000838,\n",
       "        0.01959841, -0.03943566, -0.01355046,  0.00896135, -0.02441297])"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[word2idx['zarett']][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the $\\mathbf{X}$ and $\\mathbf{Y}$ Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now create the input and output sequences with numerical indices. First, convert the \n",
    "$\\mathbf{X}_\\text{train\\_symbs}$ and $\\mathbf{Y}_\\text{train\\_symbs}$ \n",
    "lists of symbols in lists of numbers using the indices you created. Call them `X_train_idx` and `Y_train_idx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_idx = []\n",
    "for sentence in X_train_symbs:\n",
    "    sentence_idx = []\n",
    "    for word in sentence:\n",
    "        sentence_idx.append(word2idx[word])\n",
    "    X_train_idx.append(sentence_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_idx = []\n",
    "for sentence in Y_train_symbs:\n",
    "    sentence_idx = []\n",
    "    for chunk in sentence:\n",
    "        sentence_idx.append(chunk2idx[chunk])\n",
    "    Y_train_idx.append(sentence_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word indices of the three first sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[107701, 189360, 358640, 291209, 193879, 388606, 143496, 362305, 353285, 56501, 328878, 126632, 187522, 364843, 148777, 152124, 326524, 454, 131007, 152124, 306232, 363097, 454, 144953, 362305, 331257, 43426, 347508, 189267, 155109, 200552, 55175, 63614, 154, 259236, 120001, 873], [97171, 269136, 358640, 143112, 262191, 219534, 154, 307829, 106548, 362305, 43426, 149626, 249511, 288933, 174855, 177388, 362305, 293204, 43426, 154301, 189360, 344283, 274536, 358640, 279589, 386150, 873], [88319, 54890, 304156, 372747, 349558, 152124, 344283, 174855, 72318, 139858, 88675, 358640, 97171, 154, 144970, 362305, 56361, 57639, 261034, 288933, 240241, 189360, 180283, 234487, 183252, 340448, 218722, 360423, 873]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_idx[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chunk tag indices of the three first sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6, 7, 6, 16, 11, 21, 21, 21, 21, 6, 16, 16, 9, 6, 16, 7, 6, 22, 1, 7, 6, 6, 22, 11, 21, 21, 6, 16, 16, 7, 6, 16, 16, 6, 16, 16, 22], [22, 7, 6, 16, 6, 16, 6, 16, 16, 7, 6, 16, 16, 16, 11, 21, 21, 21, 6, 16, 7, 6, 7, 6, 16, 16, 22], [22, 6, 11, 6, 16, 7, 6, 11, 21, 21, 7, 6, 16, 6, 16, 11, 21, 6, 16, 16, 16, 7, 6, 16, 16, 16, 6, 16, 22]]\n"
     ]
    }
   ],
   "source": [
    "print(Y_train_idx[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, pad the sentences using the `pad_sequences` function from Keras. After padding, the second sentence you look like (the indices are not necessarily the same).\n",
    "```\n",
    "x = [ 97171, 269136, 358640, 143112, 262191, 219534,    154, 307829,\n",
    "       106548, 362305,  43426, 149626, 249511, 288933, 174855, 177388,\n",
    "       362305, 293204,  43426, 154301, 189360, 344283, 274536, 358640,\n",
    "       279589, 386150,    873,      0,      0,      0,      0,      0,\n",
    "            0,      0,      0,      0,      0,      0,      0,      0,\n",
    "            0,      0,      0,      0,      0,      0,      0,      0,\n",
    "            0,      0,      0,      0,      0,      0,      0,      0,\n",
    "            0,      0,      0,      0,      0,      0,      0,      0,\n",
    "            0,      0,      0,      0,      0,      0,      0,      0,\n",
    "            0,      0,      0,      0,      0,      0]\n",
    "y = [22,  7,  6, 16,  6, 16,  6, 16, 16,  7,  6, 16, 16, 16, 11, 21, 21,\n",
    "       21,  6, 16,  7,  6,  7,  6, 16, 16, 22,  0,  0,  0,  0,  0,  0,  0,\n",
    "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0]\n",
    "```\n",
    "\n",
    "You will call the results `X_train_padded` and `Y_train_padded`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_padded = pad_sequences(X_train_idx, padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_padded = pad_sequences(Y_train_idx, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 97171, 269136, 358640, 143112, 262191, 219534,    154, 307829,\n",
       "       106548, 362305,  43426, 149626, 249511, 288933, 174855, 177388,\n",
       "       362305, 293204,  43426, 154301, 189360, 344283, 274536, 358640,\n",
       "       279589, 386150,    873,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0], dtype=int32)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_padded[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22,  7,  6, 16,  6, 16,  6, 16, 16,  7,  6, 16, 16, 16, 11, 21, 21,\n",
       "       21,  6, 16,  7,  6,  7,  6, 16, 16, 22,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0], dtype=int32)"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_padded[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the indices in the $\\mathbf{Y}_\\text{train\\_padded}$ vector into one-hot encoded vectors. Use `to_categorical()`. Call the result `Y_train_padded_vectorized`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_padded_vectorized = to_categorical(Y_train_padded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_padded_vectorized[1][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your network consisting of one embedding layer, a simple recurrent neural network, either RNN or LSTM, and a dense layer. You will initialize the embedding layer with `embedding_matrix`. You will set the embeddings as nontrainable first. You may try other configurations after. As number of RNN/LSTM units use 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, Masking, Embedding\n",
    "\n",
    "model1 = Sequential() # TODO Prediction gives wrong shape\n",
    "\n",
    "model1.add( \n",
    "    Embedding(input_dim=401466,\n",
    "              input_length = 100,\n",
    "              output_dim=100,\n",
    "              embeddings_initializer=initializers.Constant(embedding_matrix),\n",
    "              trainable=False, mask_zero = True))\n",
    "\n",
    "model1.add(layers.Bidirectional(LSTM(LSTM_HIDDEN_DIM, return_sequences=True))) # 128\n",
    "#model1.add((layers.SimpleRNN(LSTM_HIDDEN_DIM, return_sequences=True))) # 128 # accuracy = 0.8540963359407163 ep 10\n",
    "# model1.add(layers.Bidirectional(LSTM(LSTM_HIDDEN_DIM, return_sequences=True)))\n",
    "\n",
    "model1.add(Dense(23, activation='softmax')) # chunks + 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile your code with a loss, optimizer, and metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(\n",
    "    optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8936"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100), dtype=tf.float32, name='embedding_39_input'), name='embedding_39_input', description=\"created by layer 'embedding_39_input'\"), but it was called on an input with incompatible shape (None, 78).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100), dtype=tf.float32, name='embedding_39_input'), name='embedding_39_input', description=\"created by layer 'embedding_39_input'\"), but it was called on an input with incompatible shape (None, 78).\n",
      "280/280 [==============================] - 34s 99ms/step - loss: 0.2485 - accuracy: 0.7529\n",
      "Epoch 2/10\n",
      "280/280 [==============================] - 28s 99ms/step - loss: 0.1162 - accuracy: 0.8881\n",
      "Epoch 3/10\n",
      "280/280 [==============================] - 28s 100ms/step - loss: 0.0898 - accuracy: 0.9127\n",
      "Epoch 4/10\n",
      "280/280 [==============================] - 28s 99ms/step - loss: 0.0754 - accuracy: 0.9274\n",
      "Epoch 5/10\n",
      "280/280 [==============================] - 28s 99ms/step - loss: 0.0657 - accuracy: 0.9367\n",
      "Epoch 6/10\n",
      "280/280 [==============================] - 28s 101ms/step - loss: 0.0587 - accuracy: 0.9431\n",
      "Epoch 7/10\n",
      "280/280 [==============================] - 28s 101ms/step - loss: 0.0529 - accuracy: 0.9488\n",
      "Epoch 8/10\n",
      "280/280 [==============================] - 28s 100ms/step - loss: 0.0482 - accuracy: 0.9535\n",
      "Epoch 9/10\n",
      "280/280 [==============================] - 28s 101ms/step - loss: 0.0439 - accuracy: 0.9574\n",
      "Epoch 10/10\n",
      "280/280 [==============================] - 31s 111ms/step - loss: 0.0405 - accuracy: 0.9610\n"
     ]
    }
   ],
   "source": [
    "history = model1.fit(X_train_padded, Y_train_padded_vectorized, \n",
    "                     epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we visualize the training curves. Ideally, we would compare them with those of a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['accuracy']\n",
    "loss = history.history['loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "plt.title('Training accuracies')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.title('Training losses')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the model. (This takes a long time as you have to save the embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 13:55:02.130333: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: keras_model/assets\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Message third_party.py.keras.protobuf.SavedMetadata exceeds maximum protobuf size of 2GB: 2538073121",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/filippahansen/Desktop/Språkteknologi/edan20-rep/notebooks/4-chunker_keras_fmh.ipynb Cell 112\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/filippahansen/Desktop/Spr%C3%A5kteknologi/edan20-rep/notebooks/4-chunker_keras_fmh.ipynb#Y204sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model1\u001b[39m.\u001b[39;49msave(\u001b[39m\"\u001b[39;49m\u001b[39mkeras_model\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/engine/training.py:2145\u001b[0m, in \u001b[0;36mModel.save\u001b[0;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m   2103\u001b[0m \u001b[39m\"\"\"Saves the model to Tensorflow SavedModel or a single HDF5 file.\u001b[39;00m\n\u001b[1;32m   2104\u001b[0m \n\u001b[1;32m   2105\u001b[0m \u001b[39mPlease see `tf.keras.models.save_model` or the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2142\u001b[0m \u001b[39m```\u001b[39;00m\n\u001b[1;32m   2143\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2144\u001b[0m \u001b[39m# pylint: enable=line-too-long\u001b[39;00m\n\u001b[0;32m-> 2145\u001b[0m save\u001b[39m.\u001b[39;49msave_model(\u001b[39mself\u001b[39;49m, filepath, overwrite, include_optimizer, save_format,\n\u001b[1;32m   2146\u001b[0m                 signatures, options, save_traces)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/saving/save.py:149\u001b[0m, in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m   \u001b[39mwith\u001b[39;00m generic_utils\u001b[39m.\u001b[39mSharedObjectSavingScope():\n\u001b[0;32m--> 149\u001b[0m     saved_model_save\u001b[39m.\u001b[39;49msave(model, filepath, overwrite, include_optimizer,\n\u001b[1;32m    150\u001b[0m                           signatures, options, save_traces)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/saving/saved_model/save.py:98\u001b[0m, in \u001b[0;36msave\u001b[0;34m(model, filepath, overwrite, include_optimizer, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m     94\u001b[0m   metadata \u001b[39m=\u001b[39m generate_keras_metadata(saved_nodes, node_paths)\n\u001b[1;32m     96\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39mGFile(\n\u001b[1;32m     97\u001b[0m     os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(filepath, constants\u001b[39m.\u001b[39mSAVED_METADATA_PATH), \u001b[39m\"\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m w:\n\u001b[0;32m---> 98\u001b[0m   w\u001b[39m.\u001b[39mwrite(metadata\u001b[39m.\u001b[39;49mSerializeToString(deterministic\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m))\n\u001b[1;32m    100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m include_optimizer:\n\u001b[1;32m    101\u001b[0m   model\u001b[39m.\u001b[39moptimizer \u001b[39m=\u001b[39m orig_optimizer\n",
      "\u001b[0;31mValueError\u001b[0m: Message third_party.py.keras.protobuf.SavedMetadata exceeds maximum protobuf size of 2GB: 2538073121"
     ]
    }
   ],
   "source": [
    "model1.save(\"keras_model\") # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading in again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    " model1 = tensorflow.keras.models.load_model(\"keras_model\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try the model on a test sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'The United States might collapsez'.lower().split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the sentence words to indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_word_idxs = []\n",
    "for word in sentence:\n",
    "    if word in word2idx.keys():\n",
    "        sentence_word_idxs.append(word2idx[word])\n",
    "    else:\n",
    "        sentence_word_idxs.append(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The indices. Note the 1 at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence ['the', 'united', 'states', 'might', 'collapsez']\n",
      "Sentence word indexes [358640, 373606, 343335, 245002, 1]\n"
     ]
    }
   ],
   "source": [
    "print('Sentence', sentence)\n",
    "print('Sentence word indexes', sentence_word_idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the chunks. Call the variable `sent_chunk_predictions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100), dtype=tf.float32, name='embedding_39_input'), name='embedding_39_input', description=\"created by layer 'embedding_39_input'\"), but it was called on an input with incompatible shape (None, 5).\n"
     ]
    }
   ],
   "source": [
    "sent_chunk_predictions = model1.predict([sentence_word_idxs]) # or pad first?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5, 23)"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_chunk_predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimated probabilities of the first chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.92615033e-07, 1.13566284e-05, 1.18309676e-04, 1.70594660e-06,\n",
       "       6.16773514e-06, 1.85956469e-05, 9.98158038e-01, 8.52556550e-05,\n",
       "       1.35647360e-06, 1.10089331e-05, 4.63781191e-07, 5.97897497e-07,\n",
       "       6.22726759e-07, 9.04149204e-07, 9.22661002e-07, 2.54471024e-06,\n",
       "       3.29985283e-04, 1.11708869e-06, 1.11040890e-06, 4.28366207e-07,\n",
       "       1.50716198e-06, 5.29556985e-08, 1.24781765e-03], dtype=float32)"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_chunk_predictions[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply argmax to select the chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the: B-NP\n",
      "united: I-NP\n",
      "states: I-NP\n",
      "might: B-VP\n",
      "collapsez /ukn: I-VP\n"
     ]
    }
   ],
   "source": [
    "for word_nbr, chunk_predictions in enumerate(sent_chunk_predictions[0]):\n",
    "    if sentence_word_idxs[word_nbr] in idx2word:\n",
    "        print(idx2word[sentence_word_idxs[word_nbr]], end=': ')\n",
    "    else:\n",
    "        print(sentence[word_nbr], '/ukn', end=': ')\n",
    "    print(idx2chunk.get(np.argmax(chunk_predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'form': 'Rockwell', 'pos': 'NNP', 'chunk': 'B-NP'},\n",
       "  {'form': 'said', 'pos': 'VBD', 'chunk': 'B-VP'},\n",
       "  {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       "  {'form': 'agreement', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       "  {'form': 'calls', 'pos': 'VBZ', 'chunk': 'B-VP'},\n",
       "  {'form': 'for', 'pos': 'IN', 'chunk': 'B-SBAR'},\n",
       "  {'form': 'it', 'pos': 'PRP', 'chunk': 'B-NP'},\n",
       "  {'form': 'to', 'pos': 'TO', 'chunk': 'B-VP'},\n",
       "  {'form': 'supply', 'pos': 'VB', 'chunk': 'I-VP'},\n",
       "  {'form': '200', 'pos': 'CD', 'chunk': 'B-NP'},\n",
       "  {'form': 'additional', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
       "  {'form': 'so-called', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
       "  {'form': 'shipsets', 'pos': 'NNS', 'chunk': 'I-NP'},\n",
       "  {'form': 'for', 'pos': 'IN', 'chunk': 'B-PP'},\n",
       "  {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       "  {'form': 'planes', 'pos': 'NNS', 'chunk': 'I-NP'},\n",
       "  {'form': '.', 'pos': '.', 'chunk': 'O'}]]"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentences = read_sentences(test_file)\n",
    "test_dict = split_rows(test_sentences, column_names)\n",
    "test_dict[1:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the $\\mathbf{X}$ and $\\mathbf{Y}$ sequences of symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test: ['rockwell', 'said', 'the', 'agreement', 'calls', 'for', 'it', 'to', 'supply', '200', 'additional', 'so-called', 'shipsets', 'for', 'the', 'planes', '.']\n",
      "Y_test ['B-NP', 'B-VP', 'B-NP', 'I-NP', 'B-VP', 'B-SBAR', 'B-NP', 'B-VP', 'I-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'O']\n"
     ]
    }
   ],
   "source": [
    "X_test_symbs, Y_test_symbs = build_sequences(test_dict, key_x='form', key_y='chunk')\n",
    "print('X_test:', X_test_symbs[1])\n",
    "print('Y_test', Y_test_symbs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the $\\mathbf{X}$ symbol sequence into an index sequence and pad it. Call the results `X_test_idx` and `X_test_padded`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_idx = []\n",
    "for sentence in X_test_symbs:\n",
    "    temp_idx = []\n",
    "    for word in sentence:\n",
    "        if word in word2idx.keys():\n",
    "            temp_idx.append(word2idx[word])\n",
    "        else:\n",
    "            temp_idx.append(1)\n",
    "    X_test_idx.append(temp_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_padded = pad_sequences(X_test_idx, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test_idx: [311438, 316957, 358640, 48789, 90494, 152124, 194623, 362305, 349553, 17495, 46648, 337426, 1, 152124, 358640, 287224, 873]\n",
      "X_test_padded: [311438 316957 358640  48789  90494 152124 194623 362305 349553  17495\n",
      "  46648 337426      1 152124 358640 287224    873      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0]\n"
     ]
    }
   ],
   "source": [
    "print('X_test_idx:', X_test_idx[1])\n",
    "print('X_test_padded:', X_test_padded[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2012, 70)"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_padded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the chunks. Call the result `Y_test_hat_probs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_X_test_idx = pad_sequences(X_test_idx, padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100), dtype=tf.float32, name='embedding_39_input'), name='embedding_39_input', description=\"created by layer 'embedding_39_input'\"), but it was called on an input with incompatible shape (None, 70).\n"
     ]
    }
   ],
   "source": [
    "Y_test_hat_probs = model1.predict([padded_X_test_idx]) # # TODO also prediction wrong shape?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions [[3.4572970e-06 1.7897171e-05 4.1545331e-06 ... 1.1844604e-05\n",
      "  2.6501586e-05 2.4319351e-04]\n",
      " [2.2047944e-07 2.5011714e-06 4.2832093e-05 ... 1.0561417e-06\n",
      "  1.1413714e-04 4.7376934e-03]\n",
      " [1.2513991e-07 7.5448761e-06 1.0287693e-05 ... 6.6604417e-07\n",
      "  4.8680943e-07 9.1996405e-04]\n",
      " ...\n",
      " [4.2494070e-02 4.3506939e-02 4.4601221e-02 ... 4.3238513e-02\n",
      "  4.3629162e-02 4.9249280e-02]\n",
      " [4.2494070e-02 4.3506939e-02 4.4601221e-02 ... 4.3238513e-02\n",
      "  4.3629162e-02 4.9249280e-02]\n",
      " [4.2494070e-02 4.3506939e-02 4.4601221e-02 ... 4.3238513e-02\n",
      "  4.3629162e-02 4.9249280e-02]]\n"
     ]
    }
   ],
   "source": [
    "print('Predictions', Y_test_hat_probs[1]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now predict the whole test set and we store the results in each dictionary with the key `pchunk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent, y_hat_probs in zip(test_dict, Y_test_hat_probs):\n",
    "    sent_len = len(sent)\n",
    "    y_hat_probs = y_hat_probs[:sent_len]\n",
    "    y_hat = map(np.argmax, y_hat_probs)\n",
    "    for word, ner_hat in zip(sent, y_hat):\n",
    "        word['pchunk'] = idx2chunk[ner_hat]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sentence example: `chunk` is the hand annotation and `pchunk` is the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'form': 'Rockwell', 'pos': 'NNP', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'said', 'pos': 'VBD', 'chunk': 'B-VP', 'pchunk': 'B-VP'},\n",
       " {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'agreement', 'pos': 'NN', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'calls', 'pos': 'VBZ', 'chunk': 'B-VP', 'pchunk': 'B-VP'},\n",
       " {'form': 'for', 'pos': 'IN', 'chunk': 'B-SBAR', 'pchunk': 'B-PP'},\n",
       " {'form': 'it', 'pos': 'PRP', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'to', 'pos': 'TO', 'chunk': 'B-VP', 'pchunk': 'B-VP'},\n",
       " {'form': 'supply', 'pos': 'VB', 'chunk': 'I-VP', 'pchunk': 'B-NP'},\n",
       " {'form': '200', 'pos': 'CD', 'chunk': 'B-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'additional', 'pos': 'JJ', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'so-called', 'pos': 'JJ', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'shipsets', 'pos': 'NNS', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'for', 'pos': 'IN', 'chunk': 'B-PP', 'pchunk': 'B-PP'},\n",
       " {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'planes', 'pos': 'NNS', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': '.', 'pos': '.', 'chunk': 'O', 'pchunk': 'O'}]"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dict[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the test set in a file to evaluate the performance of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['form', 'pos', 'chunk', 'pchunk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(file, corpus_dict, column_names):\n",
    "    \"\"\"\n",
    "    Saves the corpus in a file\n",
    "    :param file:\n",
    "    :param corpus_dict:\n",
    "    :param column_names:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    with open(file, 'w', encoding='utf8') as f_out:\n",
    "        i += 1\n",
    "        for sentence in corpus_dict:\n",
    "            sentence_lst = []\n",
    "            for row in sentence:\n",
    "                items = map(lambda x: row.get(x, '_'), column_names)\n",
    "                sentence_lst += ' '.join(items) + '\\n'\n",
    "            sentence_lst += '\\n'\n",
    "            f_out.write(''.join(sentence_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = 'test_model1.out'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(outfile, test_dict, column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9004743280352834"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = open(outfile, encoding='utf8').read().splitlines()\n",
    "res = conlleval.evaluate(lines)\n",
    "chunker_score = res['overall']['chunks']['evals']['f1']\n",
    "chunker_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.8983791168981722 bidi lstm non trainable 10 epochs\n",
    "# 0.8954656530002717 bidi lstm non trainable 15 epochs\n",
    "# 0.9038243480053603 bidi lstm trainable 10 epochs\n",
    "# 0.9071813322795999 bidi lstm trainable 15 epochs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will carry out experiments with two different recurrent networks: RNN and LSTM. You will also try at least two sets of parameters per network. In your report, you will present your results in a table like this one:\n",
    "\n",
    "|Method|Parameters|Score|\n",
    "|------|-----|-----|\n",
    "|Baseline|  xx | xx |\n",
    "|RNN|  xx |xx |\n",
    "|RNN |  xx |xx |\n",
    "|LSTM |  xx |xx |\n",
    "|LSTM |  xx |xx |\n",
    "|  Akbik et al.|  xx|xx |\n",
    "\n",
    "The baseline is the one from the CoNLL 2000 site"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##epoker,\n",
    "trainable,\n",
    "direction eller inte,\n",
    "baseline 0.77,\n",
    "Akbik et al. 0.96 finns i beskrivningen också"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you have written all the code and run all the cells, fill in your ID and as well as the name of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STIL_ID = [\"student_1\", \"student_2\"] # Write your stil ids as a list\n",
    "CURRENT_NOTEBOOK_PATH = os.path.join(os.getcwd(), \n",
    "                                     \"4-chunker_solution.ipynb\") # Write the name of your notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The submission code will send your answer. It consists of your best score and the confirmed entities. You need a score of more than 90 to pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"chunker_score\": 0.9004743280352834}'"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "ANSWER = json.dumps({'chunker_score': chunker_score})\n",
    "ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the moment of truth:\n",
    "1. Save your notebook and\n",
    "2. Run the cells below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENT_NOTEBOOK_PATH = \"/Users/filippahansen/Desktop/Språkteknologi/edan20-rep/notebooks/4-chunker_keras_fmh.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBMISSION_NOTEBOOK_PATH = CURRENT_NOTEBOOK_PATH + \".submission.bz2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2\n",
    "ASSIGNMENT = 4\n",
    "API_KEY = \"f581ba347babfea0b8f2c74a3a6776a7\"\n",
    "\n",
    "# Copy and compress current notebook\n",
    "with bz2.open(SUBMISSION_NOTEBOOK_PATH, mode=\"wb\") as fout:\n",
    "    with open(CURRENT_NOTEBOOK_PATH, \"rb\") as fin:\n",
    "        fout.write(fin.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'msg': None,\n",
       " 'status': 'correct',\n",
       " 'signature': 'cfe2f0e3ad2fb210978ecf29ae258a861856291a881cf2740bc8d3cbcd42f576fc5bed7da423aeaa1824f6287766ffe3c2f9cdcde64009673a0c5ee472003812',\n",
       " 'submission_id': 'd29342df-42e2-4d8c-82d5-15141c1cc500'}"
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = requests.post(\"https://vilde.cs.lth.se/edan20checker/submit\", \n",
    "                    files={\"notebook_file\": open(SUBMISSION_NOTEBOOK_PATH, \"rb\")}, \n",
    "                    data={\n",
    "                        \"stil_id\": \"fi6369ha-s\",\n",
    "                        \"assignment\": ASSIGNMENT,\n",
    "                        \"answer\": ANSWER,\n",
    "                        \"api_key\": API_KEY,\n",
    "                    },\n",
    "               verify=True)\n",
    "\n",
    "# from IPython.display import display, JSON\n",
    "res.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Turning in your assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now your are done with the program. To complete this assignment, you will:\n",
    "1. Write a short individual report on your program. You will describe the architecture your used the different experiments you carried out and your results.\n",
    "2. Read the article, <a href=\"https://www.aclweb.org/anthology/C18-1139\"><i>Contextual String Embeddings for Sequence Labeling</i></a> by Akbik et al. (2018) and outline the main differences between their system and yours. A LSTM is a type of recurrent neural network, while CRF is a sort of beam search. You will tell the performance they reach on the corpus you used in this laboratory.\n",
    "\n",
    "Submit your report as well as your notebook (for archiving purposes) to Canvas: https://canvas.education.lu.se/. To write your report, you can either\n",
    "1. Write directly your text in Canvas, or\n",
    "2. Use Latex and Overleaf (www.overleaf.com). This will probably help you structure your text. You will then upload a PDF file in Canvas.\n",
    "\n",
    "The submission deadline is October 7, 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
